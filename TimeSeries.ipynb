{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1ygjZkcgEBX3",
    "outputId": "36a5628d-8727-4df8-e0a5-6cf6a3b51ad6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "# prepare data for machine learning model\n",
    "# https://machinelearningmastery.com/random-forest-for-time-series-forecasting/\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Given univariate time series (equal datasteps)\n",
    "raw_seq = pd.Series([91.57, 91.56, 91.40, 91.39, 91.20, 90.90, 90.99,\n",
    "                     91.17, 90.98, 91.11, 91.20, 90.92, 90.73, 90.79, 90.86, 90.83,\n",
    "                     90.80, 90.21, 90.10, 90.10, 89.66, 89.81, 89.40, 89.34, 89.16,\n",
    "                     88.71, 89.28, 89.36, 89.64, 89.53, 89.32, 89.14, 89.41, 89.53,\n",
    "                     89.16, 88.98, 88.50, 88.63, 88.62, 88.76, 89.07, 88.47, 88.41,\n",
    "                     88.57, 88.23, 87.93, 87.88, 88.18, 88.04, 88.18, 88.78, 89.29,\n",
    "                     89.14, 89.14, 89.42, 89.26, 89.37, 89.51, 89.66, 89.39, 89.02,\n",
    "                     89.05, 88.97, 88.57, 88.44, 88.52, 87.92, 87.71, 87.52, 87.37,\n",
    "                     87.27, 87.07, 86.83, 86.88, 87.48, 87.30, 87.87, 87.85, 87.83,\n",
    "                     87.40, 86.89, 87.38, 87.48, 87.21, 87.02, 87.10, 87.02, 87.07,\n",
    "                     86.74, 86.35, 86.32, 86.77, 86.77, 86.49, 86.02, 85.52, 85.02,\n",
    "                     86.02, 85.52, 85.02, 84.42, 85.29])\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Analysis of Time Series\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "# visualization\n",
    "raw_seq.plot()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Raw sequence\")\n",
    "plt.show()\n",
    "\n",
    "# Detrending\n",
    "from scipy import signal\n",
    "detrended = signal.detrend(raw_seq.values)\n",
    "plt.plot(detrended)\n",
    "plt.title('Raw sequence detrended by subtracting the least squares fit')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "# todo: modify the code to deseasonalize with the assumption of additive model. Compare the results.\n",
    "# Seasonal decomposition for multiplicative model\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result_mul = seasonal_decompose(raw_seq, model='multiplicative', period=12)\n",
    "# Deseasonalize\n",
    "deseasonalized = raw_seq.values / result_mul.seasonal\n",
    "# Plot\n",
    "plt.plot(deseasonalized)\n",
    "plt.title('Deseasonalized for multiplicative model')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "## Test for seasonality\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "# Draw Plot (for seasonal data, multiple peaks should appear)\n",
    "autocorrelation_plot(raw_seq.values.tolist())\n",
    "plt.show()\n",
    "\n",
    "# check the histogram of values\n",
    "plt.hist(raw_seq)\n",
    "plt.show()\n",
    "\n",
    "# todo: modify the function to check if time series is stationary by comparing custom number of intervals\n",
    "# check if the time series is stationary (has the same characteristics in both intervals)\n",
    "def timeSeriesSplitMeanVar(ts):\n",
    "    split = len(ts) // 2\n",
    "    X1, X2 = ts[0:split], ts[split:]\n",
    "    mean1, mean2 = X1.mean(), X2.mean()\n",
    "    var1, var2 = X1.var(), X2.var()\n",
    "    print('mean1=%f, mean2=%f' % (mean1, mean2))\n",
    "    print('variance1=%f, variance2=%f' % (var1, var2))\n",
    "timeSeriesSplitMeanVar(raw_seq)\n",
    "\n",
    "# todo: check if the raw_seq, deseasonalized and detrended time series are stationary in two and more intervals\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "ARIMA\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "model = ARIMA(raw_seq, order=(1, 0, 1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "forecast = model_fit.get_forecast(steps=10)\n",
    "# Split the data into train and test\n",
    "train_size = int(len(raw_seq) * 0.8)\n",
    "train, test = raw_seq[0:train_size], raw_seq[train_size:len(raw_seq)]\n",
    "\n",
    "# todo: use at least 6 combinations of ARIMA parameters and compare the obtained results\n",
    "# Fit the ARIMA model on the training dataset\n",
    "model_train = ARIMA(train, order=(5, 2, 1)) # (p, d, q)\n",
    "model_train_fit = model_train.fit()\n",
    "\n",
    "# Forecast on the test dataset\n",
    "test_forecast = model_train_fit.get_forecast(steps=len(test))\n",
    "test_forecast_series = pd.Series(test_forecast.predicted_mean, index=test.index)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(test, test_forecast_series)\n",
    "plt.plot(train, label='Training Data')\n",
    "plt.plot(test, label='Actual Data', color='orange')\n",
    "plt.plot(test_forecast_series, label='Forecasted Data', color='green')\n",
    "plt.title('ARIMA Model Evaluation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Random forest\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# validate the model for one step forward (valid_no times)\n",
    "# todo: compare the validation error with different number of estimators\n",
    "# todo: compare the validation error with different number of previous values used in the model\n",
    "valid_no = 10\n",
    "raw_seq.plot(color = \"blue\")\n",
    "y_valid = list()\n",
    "for i in range(valid_no):\n",
    "    # split into samples\n",
    "    X , y = split_sequence(raw_seq[:(-valid_no+i)], n_steps)\n",
    "    model = RandomForestRegressor(n_estimators=50)\n",
    "    model.fit(X, y)\n",
    "    x_input = np.array(raw_seq[(-valid_no+i-n_steps):(-valid_no+i)])\n",
    "    x_input = x_input.reshape((1, n_steps))\n",
    "    yhat = model.predict(x_input)\n",
    "    y_valid.append(yhat)\n",
    "\n",
    "plt.plot(np.arange((len(raw_seq)-valid_no),(len(raw_seq)), 1), y_valid,'mo',label = \"one-step validation\")\n",
    "print(mean_squared_error(raw_seq[(-valid_no):], y_valid))\n",
    "plt.show()\n",
    "\n",
    "x_input = np.array(raw_seq[(-n_steps):])\n",
    "\n",
    "xTest = pd.DataFrame([85.32])\n",
    "x_input = x_input.reshape((1, n_steps))\n",
    "yhat = model.predict(x_input)\n",
    "print('predicted=%f, actual=%f' % (yhat, xTest[0][0]))\n",
    "raw_seq.plot(color = 'b', label = \"train\")\n",
    "plt.plot(len(raw_seq), yhat, 'ro', label = \"predicted\")\n",
    "plt.plot(len(raw_seq), xTest[0][0], 'go', label = \"actual\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "MLP\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "# todo: compare the test error with different number of layers and neurons\n",
    "# todo: compare the test error with different number of previous values used in the model\n",
    "import matplotlib.pyplot as plt\n",
    "MLPmodel = tf.keras.Sequential()\n",
    "MLPmodel.add(tf.keras.layers.Dense(100, activation='relu', input_dim=n_steps))\n",
    "MLPmodel.add(tf.keras.layers.Dense(1))\n",
    "MLPmodel.compile(optimizer='adam', loss='mse')\n",
    "model_history = MLPmodel.fit(X, y, epochs=20, verbose=1)\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss function\")\n",
    "plt.show()\n",
    "x_input = np.array(raw_seq[(-n_steps):])\n",
    "\n",
    "xTest = pd.DataFrame([85.32])\n",
    "x_input = x_input.reshape((1, n_steps))\n",
    "yhat = MLPmodel.predict(x_input)\n",
    "print('predicted=%f, actual=%f' % (yhat[0][0], xTest[0][0]))\n",
    "raw_seq.plot(color = 'b', label = \"train\")\n",
    "plt.plot(len(raw_seq), yhat, 'ro', label = \"predicted\")\n",
    "plt.plot(len(raw_seq), xTest[0][0], 'go', label = \"actual\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILGcoqkLEIQT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SMM24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
